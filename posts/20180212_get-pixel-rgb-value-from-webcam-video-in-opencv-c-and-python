This post will go through a simple OpenCV utility I made that allows you to get the RGB value of any pixel in a snapshot taken from a webcam's video feed. The program presents the user with a "Video" window, which displays the source video from the webcam, and a "Snapshot" window, which displays the last snapshot taken; a snapshot of the current frame of the video is taken by pressing the "T" key on the keyboard. Finally, there's a "Color" window; when the user clicks anywhere within the Snapshot window, the color of the pixel they clicked on fills the Color window, and the RGB value corresponding to the color is displayed. This allows the user to check visually that they did, in fact, click on the correct pixel in the Snapshot window and that the RGB value corresponds to the color they actually wanted. Here's a demonstration:

<iframe width="700" height="394" src="https://www.youtube.com/embed/EvBfcM2Y-Kk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<h1>The code</h1>

Both <a href="https://github.com/nrsyed/computer-vision/blob/master/get_video_pixel/get_video_pixel.cpp" rel="noopener" target="_blank">the C++ version</a> and <a href="https://github.com/nrsyed/computer-vision/blob/master/get_video_pixel/get_video_pixel.py" rel="noopener" target="_blank">the Python version</a> of the program can be found on Github. Below, we'll go through them simultaneously. For each block of code, I'll start with the Python version to explain the gist and touch on Python-specific implementation details, then show the C++ version and discuss C++-specific implementation details.

<em>Python</em>
<pre class="line-numbers"><code class="language-python">import numpy as np
import cv2

COLOR_ROWS = 80
COLOR_COLS = 250</code></pre>
<br class="">
<em>C++</em>
<pre class="line-numbers"><code class="language-cpp">#include &lt;iostream>
#include &lt;string>
#include &lt;opencv2/opencv.hpp>
#include &lt;opencv2/videoio.hpp>
#include &lt;opencv2/highgui.hpp>
#include &lt;opencv2/imgproc.hpp>

#define COLOR_ROWS 80
#define COLOR_COLS 250</code></pre>

First, our imports/globals and includes/defines. <code>COLOR_ROWS</code> and <code>COLOR_COLS</code> are used to set the size of the Color window or, more specifically, the size of the image that fills the Color window.

<em>Python</em>
<pre class="line-numbers" data-start=7><code class="language-python">capture = cv2.VideoCapture(0)
if not capture.isOpened():
    raise RuntimeError('Error opening VideoCapture.')

(grabbed, frame) = capture.read()
snapshot = np.zeros(frame.shape, dtype=np.uint8)
cv2.imshow('Snapshot', snapshot)

colorArray = np.zeros((COLOR_ROWS, COLOR_COLS, 3), dtype=np.uint8)
cv2.imshow('Color', colorArray)</code></pre>

First, we initialize a <code>VideoCapture</code> object, which I've named <code>capture</code>, on <b>line 7</b>. The input to the constructor, <code>0</code> (in <code>cv2.VideoCapture(0)</code>) is the device ID of the camera; if there's only one webcam connected, you can simply provide <code>0</code>. On <b>lines 8-9</b>, we check that the previous step was successful. On <b>line 11</b> we use <code>capture.read()</code> to grab, decode, and return the first frame of the video in the form of a numpy array, which we'll call <code>frame</code>. On <b>lines 12-13</b>, we use the shape of the video output <code>frame</code> to initialize <code>snapshot</code>, which is the image array that will be displayed in the Snapshot window (to start with, we initialize the snapshot array to an entirely black image using <code>np.zeros()</code>). The Snapshot window is shown with <code>cv2.imshow('Snapshot', snapshot)</code>. In a similar fashion, we initialize the color image array, <code>colorArray</code>, which will be displayed in the Color window, on <b>lines 15-16</b>.

<em>C++</em>
<pre class="line-numbers" data-start=39><code class="language-cpp">int main(int argc, char** argv) {
	cv::VideoCapture capture(0);

	if (!capture.isOpened()) {
		std::cout << "Error opening VideoCapture." << std::endl;
		return -1;
	}

	cv::Mat frame, snapshot, colorArray;
	capture.read(frame);

	snapshot = cv::Mat(frame.size(), CV_8UC3, cv::Scalar(0,0,0));
	cv::imshow("Snapshot", snapshot);

	colorArray = cv::Mat(COLOR_ROWS, COLOR_COLS, CV_8UC3, cv::Scalar(0,0,0));
	cv::imshow("Color", colorArray);</code></pre>
We achieve the same thing in the C++ version with a few different constructs (also note that the line number jump in the C++ version occurs because it's organized slightly differently than the Python version). After initializing and checking the <code>VideoCapture</code> object on <b>lines 40-45</b>, we declare <code>frame</code>, <code>snapshot</code>, and <code>colorArray</code> as <code>Mat</code> objects. On <b>line 48</b>, the first frame of the video is read into <code>frame</code>. On <b>line 50</b>, we initialize <code>snapshot</code> by providing the size of <code>frame</code>, the datatype <code>CV_8UC3</code> for the <code>Mat</code> array, and a <code>Scalar</code> object representing a black pixel, i.e., <code>cv::Scalar(0,0,0)</code>. The datatype <code>CV_8UC3</code> tells the constructor that we're creating a <code>Mat</code> object with 3 channels (the <code>C3</code> in <code>CV_8UC3</code>) whose values will be 8-bit unsigned ints (the <code>8U</code> in <code>CV_8UC3</code>). The <code>Scalar</code> object is counterintuitively named, because it's essentially a wrapper for a standard C++ <code>Vector</code> of up to 4 elements (though we only use 3 elements here). We call the same <code>Mat</code> constructor on <b>line 53</b> to initialize <code>colorArray</code>.

<em>Python</em>
<pre class="line-numbers" data-start=18><code class="language-python">def on_mouse_click(event, x, y, flags, userParams):
    if event == cv2.EVENT_LBUTTONDOWN:
        colorArray[:] = snapshot[y, x, :]
        rgb = snapshot[y, x, [2,1,0]]
        
        # From stackoverflow.com/questions/1855884/determine-font-color-based-on-background-color
        luminance = 1 - (0.299*rgb[0] + 0.587*rgb[1] + 0.114*rgb[2]) / 255
        if luminance < 0.5:
            textColor = [0,0,0]
        else:
            textColor = [255,255,255]

        cv2.putText(colorArray, str(rgb), (20, COLOR_ROWS - 20),
            fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.8, color=textColor)
        cv2.imshow('Color', colorArray)

cv2.setMouseCallback('Snapshot', on_mouse_click)</code></pre>

Next, we define the event callback function <code>on_mouse_click()</code>, which, when a pixel is clicked in the Snapshot window, will get the RGB value of the pixel and update the Color window accordingly. Although I use the term RGB (because that's the order in which we will display the values on the screen), OpenCV uses BGR by default. We will have to account for this when displaying the RGB text string. Also note that the function doesn't have to be named <code>on_mouse_click</code>—I've just called it that because it's how we'll be using it by checking, on <b>line 19</b>, if the left mouse button was clicked. On <b>line 20</b>, we extract the value of the clicked pixel and store it in <code>colorArray</code>. On <b>line 21</b>, we extract the value of the clicked pixel in RGB format and store it in <code>rgb</code>.

<b>Lines 24-28</b> determine whether the text in the Color window should be black or white, based on the <a href="https://en.wikipedia.org/wiki/Relative_luminance" rel="noopener" target="_blank">relative luminance</a> of the pixel color (the pixel color will fill the background of the Color window, and the text will be superimposed on top of it, so the text color must be chosen such that it will be readable). This is achieved by means of the formula on <b>line 24</b>, which I borrowed from <a href="https://stackoverflow.com/questions/1855884/determine-font-color-based-on-background-color" rel="noopener" target="_blank">an answer on StackOverflow</a>. On <b>lines 30-32</b>, we add the text in the appropriate <code>textColor</code> to <code>colorArray</code> by means of <code>cv2.putText()</code>, then update the Color window. Finally, <b>line 34</b> connects this callback function to the Snapshot window.

<em>C++</em>
<pre class="line-numbers" data-start=11><code class="language-cpp">void on_mouse_click(int event, int x, int y, int flags, void* ptr) {
	if (event == cv::EVENT_LBUTTONDOWN) {
		cv::Mat* snapshot = (cv::Mat*)ptr;
		cv::Vec3b pixel = snapshot->at&lt;cv::Vec3b>(cv::Point (x, y));
		int b, g, r;
		b = pixel[0];
		g = pixel[1];
		r = pixel[2];
		std::string rgbText = "[" + std::to_string(r) + ", " + std::to_string(g)
			+ ", " + std::to_string(b) + "]";

		// From stackoverflow.com/questions/1855884/determine-font-color-based-on-background-color
		float luminance = 1 - (0.299*r + 0.587*g + 0.114*b) / 255;
		cv::Scalar textColor;
		if (luminance < 0.5) {
			textColor = cv::Scalar(0,0,0);
		} else {
			textColor = cv::Scalar(255,255,255);
		}

		cv::Mat colorArray;
		colorArray = cv::Mat(COLOR_ROWS, COLOR_COLS, CV_8UC3, cv::Scalar(b,g,r));
		cv::putText(colorArray, rgbText, cv::Point2d(20, COLOR_ROWS - 20),
			cv::FONT_HERSHEY_SIMPLEX, 0.8, textColor);
		cv::imshow("Color", colorArray);
	}
}</code></pre>

The C++ counterpart to the <code>on_mouse_click()</code> function follows the same basic idea. However, unlike Python, functions in C++ do not have direct access to any scope outside their own. Therefore, we pass a pointer to <code>snapshot</code> via the last argument to <code>on_mouse_click()</code>. On <b>line 13</b>, we cast the input pointer to a <code>Mat</code> pointer. On <b>line 14</b>, we treat the pixel in <code>snapshot</code> as a <code>Vec3b</code> type, which is essentially just a <code>Vector</code> with 3 elements, and access the pixel using <code>at</code>, which requires us to specify the type (<code>&lt;cv::Vec3b></code>) and the point. The point is specified with a <code>Point</code> object, which is simply an object that possesses an <code>x</code> attribute and a <code>y</code> attribute. On lines <b>15-20</b>, we extract the RGB values and construct the text string to be displayed. The rest of this block of code is analogous to the Python version.

Returning briefly to the <code>main()</code> method, we use <code>setMouseCallback()</code> to link the callback function to the Snapshot window:

<pre class="line-numbers" data-start=55><code class="language-cpp">	cv::setMouseCallback("Snapshot", on_mouse_click, &snapshot);</code></pre>
The first argument to <code>setMouseCallback()</code> is the name of the window. The second argument is the name of the function. The third argument is for any other parameter we wish to pass—in this case, a pointer to <code>snapshot</code>. If we didn't want to pass anything else, we would simply pass <code>NULL</code>.
<br class="">
<em>Python</em>
<pre class="line-numbers" data-start=36><code class="language-python">while True:
    (grabbed, frame) = capture.read()
    cv2.imshow('Video', frame)

    if not grabbed:
        break

    keyVal = cv2.waitKey(1) & 0xFF
    if keyVal == ord('q'):
        break
    elif keyVal == ord('t'):
        snapshot = frame.copy()
        cv2.imshow('Snapshot', snapshot)

capture.release()
cv2.destroyAllWindows()</code></pre>

Lastly, we come to the main loop, which continually grabs and returns frames from the webcam video source. If this is unsuccessful (which might occur if the camera is suddenly disconnected), <b>lines 40-41</b> exit the loop. <b>Line 43</b> checks to see if a key has been pressed via <code>cv2.waitKey(1)</code>, where the <code>1</code> indicates the timeout in milliseconds. The <code>waitKey()</code> function returns a 32-bit int whose last 8 bits are the ASCII representation of the key pressed, if any key was pressed. Using the bitwise AND <code>&</code> isolates these 8 bits (0xFF is a hex value equal to 0b11111111 in binary). The built-in Python function <code>ord()</code> returns the ASCII representation of the given character. In other words, the if-elseif statement on <b>lines 44-48</b> checks whether the "q" key has been pressed, in which case it breaks the loop, or whether the "t" key has been pressed, in which case it <b>t</b>akes a snapshot by updating <code>snapshot</code> with the current frame and updating the Snapshot window with the new <code>snapshot</code>. To update the <code>snapshot</code> array, we use the numpy function <code>copy()</code>. If we didn't do this (and instead used <code>snapshot = frame</code>), <code>snapshot</code> would simply refer to <code>frame</code>, i.e., clicking in the Snapshot window would yield the current pixel value of the live webcam source, not the "frozen" snapshot.

<em>C++</em>
<pre class="line-numbers" data-start=57><code class="language-cpp">	int keyVal;
	while (1) {
		if (!capture.read(frame)) {
			break;
		}
		cv::imshow("Video", frame);

		keyVal = cv::waitKey(1) & 0xFF;
		if (keyVal == 113) {
			break;
		} else if (keyVal == 116) {
			snapshot = frame.clone();
			cv::imshow("Snapshot", snapshot);
		}
	}
	return 0;
}</code></pre>

Again, the C++ version is analogous to the Python version. The only difference is that, here, we use the actual ASCII decimal values, 113 (q) and 116 (t), for the comparisons on <b>lines 65 and 67</b>. On <b>line 68</b>, we use the <code>Mat</code> method <code>clone</code> to create a snapshot of the current frame.

That's it. I hope you've found this program (or this post) useful.
